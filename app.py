import streamlit as st
import json
import threading
import time
from streamlit_autorefresh import st_autorefresh
from database import (
    save_test_case, get_all_test_cases, delete_test_case, delete_eval_record,
    save_eval_record, get_eval_history, get_stats, get_all_models,
    get_model_summary_stats, get_model_detail_stats, get_case_summary_stats, get_case_model_ranking
)
from llm_client import call_local_llm, call_evaluator
from init_db import init_db

# åˆå§‹åŒ–æ•°æ®åº“
init_db()

st.set_page_config(page_title="Local LLM Code Benchmarker", layout="wide")

# --- åå°ä»»åŠ¡ç®¡ç†å™¨ ---
class BackgroundTaskManager:
    def __init__(self):
        self.is_running = False
        self.progress = 0.0
        self.status = "ç©ºé—²"
        self.logs = []
        self.current_case = ""
        self.total_cases = 0
        self.completed_cases = 0
        self.thread = None
        self.stop_requested = False

    def add_log(self, msg):
        timestamp = time.strftime("%H:%M:%S")
        self.logs.append(f"[{timestamp}] {msg}")
        if len(self.logs) > 100:
            self.logs.pop(0)

    def run_batch_test(self, selected_cases, temperature):
        self.is_running = True
        self.stop_requested = False
        self.progress = 0.0
        self.completed_cases = 0
        self.total_cases = len(selected_cases)
        self.logs = []
        eval_fail_count = 0

        for idx, case in enumerate(selected_cases):
            if self.stop_requested:
                self.add_log("ğŸ›‘ ä»»åŠ¡è¢«ç”¨æˆ·åœæ­¢")
                break
            
            self.current_case = case['title']
            self.status = f"æ­£åœ¨å¤„ç† ({idx+1}/{self.total_cases}): {self.current_case}"
            self.add_log(f">>> å¼€å§‹æµ‹è¯•ç”¨ä¾‹: {self.current_case}")
            
            local_res = None
            try:
                # 1. è°ƒç”¨æœ¬åœ°æ¨¡å‹
                self.add_log(f"æ­£åœ¨è¯·æ±‚æœ¬åœ°æ¨¡å‹ (10.0.0.114:8080)...")
                local_res = call_local_llm(case['source_code'], case['prompt'], temperature)
                self.add_log(f"æœ¬åœ°æ¨¡å‹å“åº”æˆåŠŸ ({local_res['completion_tokens']} tokens)")
                
                # 2. è°ƒç”¨è¯„å§”æ¨¡å‹
                self.add_log(f"æ­£åœ¨è¯·æ±‚è¯„å§”æ¨¡å‹è¿›è¡Œè¯„åˆ†...")
                eval_res = call_evaluator(case['reference_answer'], local_res['content'])
                
                if "è¯„å§”è°ƒç”¨åœ¨" in eval_res.get('reasoning', ""):
                    eval_fail_count += 1
                    self.add_log(f"âš ï¸ è¯„åˆ†å¤±è´¥ ({eval_fail_count}/3)")
                else:
                    eval_fail_count = 0
                    self.add_log(f"è¯„åˆ†å®Œæˆ: {eval_res.get('score', 0)}åˆ†")
                
                if eval_fail_count >= 3:
                    self.add_log("âŒ è¯„åˆ†æ¨¡å‹è¿ç»­å¤±è´¥ 3 æ¬¡ï¼Œåœæ­¢å…¨éƒ¨æµ‹è¯•ã€‚")
                    break

                # 3. ä¿å­˜ç»“æœ
                record_data = {
                    "case_id": case['id'],
                    "model_name": local_res['model_name'],
                    "temperature": temperature,
                    "local_response": local_res['content'],
                    "chain_of_thought": local_res['chain_of_thought'],
                    "prompt_tokens": local_res['prompt_tokens'],
                    "completion_tokens": local_res['completion_tokens'],
                    "total_time_ms": local_res['duration_ms'],
                    "tokens_per_second": local_res['tps'],
                    "prompt_tps": local_res.get('prompt_tps', 0),
                    "max_context": local_res.get('max_context', 0),
                    "eval_score": eval_res.get('score', 0),
                    "eval_comment": eval_res.get('reasoning', "")
                }
                save_eval_record(record_data)
                self.add_log(f"âœ… ç”¨ä¾‹ '{self.current_case}' ä¿å­˜æˆåŠŸ")
                
            except Exception as e:
                self.add_log(f"âŒ æ‰§è¡Œå¤±è´¥: {str(e)}")
            
            self.completed_cases += 1
            self.progress = self.completed_cases / self.total_cases

        self.is_running = False
        self.status = "å·²å®Œæˆ" if not self.stop_requested else "å·²åœæ­¢"
        self.progress = 1.0

    def start_task(self, selected_cases, temperature):
        if not self.is_running:
            self.thread = threading.Thread(target=self.run_batch_test, args=(selected_cases, temperature))
            self.thread.daemon = True
            self.thread.start()

    def stop_task(self):
        self.stop_requested = True

if "task_manager" not in st.session_state:
    st.session_state.task_manager = BackgroundTaskManager()

task_mgr = st.session_state.task_manager

# --- ä¾§è¾¹æ å¯¼èˆª ---
with st.sidebar:
    st.title("ğŸš€ LLM Benchmarker")
    menu = st.radio("èœå•", ["ç”¨ä¾‹ç®¡ç†", "æ‰§è¡Œæµ‹è¯•", "å†å²è®°å½•", "ç»Ÿè®¡åˆ†æ"])
    
    # åå°ä»»åŠ¡è¿›åº¦æ˜¾ç¤º
    if task_mgr.is_running:
        st.divider()
        st.subheader("â³ æ­£åœ¨æ‰§è¡Œæµ‹è¯•")
        st.info(task_mgr.status)
        st.progress(task_mgr.progress)
        if st.button("ğŸ›‘ åœæ­¢ä»»åŠ¡"):
            task_mgr.stop_task()
        
        # è‡ªåŠ¨åˆ·æ–°é¡µé¢ä»¥æ›´æ–°è¿›åº¦
        st_autorefresh(interval=2000, key="progress_refresh")
    elif task_mgr.status == "å·²å®Œæˆ":
        st.divider()
        st.success("âœ… æµ‹è¯•ä»»åŠ¡å·²å®Œæˆ")
        if st.button("æ¸…é™¤çŠ¶æ€"):
            task_mgr.status = "ç©ºé—²"
            st.rerun()

    st.divider()
    st.header("ğŸ“Š å…¨å±€ç»Ÿè®¡")
    stats = get_stats()
    st.metric("æµ‹è¯•ç”¨ä¾‹æ•°", stats['total_cases'])
    st.metric("æ€»è¯„æµ‹æ¬¡æ•°", stats['total_evals'])
    st.metric("å¹³å‡å¾—åˆ†", f"{stats['avg_score']:.2f}/10")
    st.metric("å¹³å‡é€Ÿåº¦", f"{stats['avg_tps']:.2f} tps")

# --- é¡µé¢ 1ï¼šç”¨ä¾‹ç®¡ç† ---
if menu == "ç”¨ä¾‹ç®¡ç†":
    st.header("ğŸ“ æµ‹è¯•ç”¨ä¾‹ç®¡ç†")
    
    # ç¼–è¾‘çŠ¶æ€ç®¡ç†
    editing_case_id = st.session_state.get("editing_case_id", None)
    edit_data = None
    if editing_case_id:
        df_cases = get_all_test_cases()
        edit_data = df_cases[df_cases['id'] == editing_case_id].iloc[0]

    form_title = "ğŸ“ ç¼–è¾‘æµ‹è¯•ç”¨ä¾‹" if editing_case_id else "â• æ–°å»ºæµ‹è¯•ç”¨ä¾‹"
    with st.expander(form_title, expanded=(editing_case_id is not None)):
        with st.form("case_form", clear_on_submit=not editing_case_id):
            title = st.text_input("ç”¨ä¾‹æ ‡é¢˜*", value=edit_data['title'] if edit_data is not None else "", placeholder="ä¾‹å¦‚ï¼šå®ç° LRU ç¼“å­˜")
            category = st.text_input("åˆ†ç±»", value=edit_data['category'] if edit_data is not None else "", placeholder="ç®—æ³• / Web / ä¿®å¤")
            
            st.write("ğŸ“‚ æºä»£ç  (æ”¯æŒå¤šæ–‡ä»¶)")
            st.info("è¯·ä»¥ JSON æ ¼å¼è¾“å…¥ï¼Œä¾‹å¦‚ï¼š`{\"main.py\": \"...\"}`ã€‚å¦‚æœæ˜¯å•æ–‡ä»¶ï¼Œå¯ç›´æ¥è¾“å…¥ä»£ç ã€‚**ç•™ç©ºåˆ™è¡¨ç¤ºä»é›¶å¼€å§‹å†™æ–°åŠŸèƒ½ã€‚**")
            
            default_source = ""
            if edit_data is not None:
                try:
                    # å°è¯•ç¾åŒ– JSON
                    src_obj = json.loads(edit_data['source_code'])
                    default_source = json.dumps(src_obj, indent=2, ensure_ascii=False) if src_obj else ""
                except:
                    default_source = edit_data['source_code']
            
            source_code_input = st.text_area("æºä»£ç å†…å®¹", value=default_source, height=200, placeholder="ç•™ç©ºè¡¨ç¤ºä»é›¶å¼€å§‹...")
            
            prompt = st.text_area("ä¿®æ”¹è¦æ±‚ (Prompt)*", value=edit_data['prompt'] if edit_data is not None else "", height=100)
            reference_answer = st.text_area("å‚è€ƒç­”æ¡ˆ", value=edit_data['reference_answer'] if edit_data is not None else "", height=150)
            
            col_btn1, col_btn2 = st.columns([1, 5])
            submit = col_btn1.form_submit_button("ä¿å­˜")
            cancel = col_btn2.form_submit_button("å–æ¶ˆç¼–è¾‘") if editing_case_id else False
            
            if cancel:
                st.session_state.editing_case_id = None
                st.rerun()

            if submit:
                if not title or not prompt:
                    st.error("æ ‡é¢˜å’Œè¦æ±‚æ˜¯å¿…å¡«é¡¹ï¼")
                else:
                    # å¤„ç†æºä»£ç ï¼šç•™ç©ºã€JSON æˆ–çº¯æ–‡æœ¬
                    if not source_code_input.strip():
                        source_dict = {}
                    else:
                        try:
                            source_dict = json.loads(source_code_input)
                        except:
                            source_dict = {"source": source_code_input}
                    
                    save_test_case(title, category, source_dict, prompt, reference_answer, case_id=editing_case_id)
                    st.success(f"ç”¨ä¾‹ '{title}' å·²ä¿å­˜ï¼")
                    st.session_state.editing_case_id = None
                    st.rerun()

    st.subheader("ç°æœ‰ç”¨ä¾‹åˆ—è¡¨")
    df_cases = get_all_test_cases()
    if not df_cases.empty:
        for _, row in df_cases.iterrows():
            with st.container(border=True):
                col1, col2, col3, col4 = st.columns([4, 1, 1, 1])
                col1.write(f"**{row['title']}** ({row['category']})")
                if col2.button("æŸ¥çœ‹", key=f"view_{row['id']}"):
                    st.session_state[f"view_case_{row['id']}"] = not st.session_state.get(f"view_case_{row['id']}", False)
                
                if col3.button("âœï¸", key=f"edit_{row['id']}"):
                    st.session_state.editing_case_id = row['id']
                    st.rerun()

                if col4.button("ğŸ—‘ï¸", key=f"del_{row['id']}"):
                    delete_test_case(row['id'])
                    if st.session_state.get("editing_case_id") == row['id']:
                        st.session_state.editing_case_id = None
                    st.rerun()
                
                if st.session_state.get(f"view_case_{row['id']}", False):
                    try:
                        src_data = json.loads(row['source_code'])
                        if not src_data:
                            st.info("ğŸ’¡ æ­¤ç”¨ä¾‹ä¸ºâ€œä»é›¶å¼€å§‹â€å¼€å‘ï¼Œæ— åˆå§‹æºä»£ç ã€‚")
                        else:
                            st.json(src_data)
                    except:
                        st.code(row['source_code'])
                    
                    st.text_area("Prompt", row['prompt'], disabled=True)
                    st.text_area("å‚è€ƒç­”æ¡ˆ", row['reference_answer'], disabled=True)
    else:
        st.info("æš‚æ— ç”¨ä¾‹ï¼Œè¯·å…ˆåˆ›å»ºä¸€ä¸ªã€‚")

# --- é¡µé¢ 2ï¼šæ‰§è¡Œæµ‹è¯• ---
elif menu == "æ‰§è¡Œæµ‹è¯•":
    st.header("ğŸ§ª æ‰§è¡Œè¯„æµ‹")
    
    if task_mgr.is_running:
        st.warning("ğŸš€ æµ‹è¯•ä»»åŠ¡æ­£åœ¨åå°è¿è¡Œä¸­...")
        st.subheader(task_mgr.status)
        st.progress(task_mgr.progress)
        
        with st.expander("ğŸ” æŸ¥çœ‹å®æ—¶æ‰§è¡Œæ—¥å¿—", expanded=True):
            st.code("\n".join(task_mgr.logs))
        
        if st.button("ğŸ›‘ åœæ­¢å½“å‰ä»»åŠ¡"):
            task_mgr.stop_task()
            st.rerun()
    else:
        df_cases = get_all_test_cases()
        if df_cases.empty:
            st.warning("è¯·å…ˆåœ¨'ç”¨ä¾‹ç®¡ç†'ä¸­åˆ›å»ºæµ‹è¯•ç”¨ä¾‹ã€‚")
        else:
            st.write("é€‰æ‹©è¦æµ‹è¯•çš„ç”¨ä¾‹ï¼š")
            selected_indices = []
            for i, row in df_cases.iterrows():
                if st.checkbox(f"{row['title']} ({row['category']})", key=f"check_{row['id']}"):
                    selected_indices.append(i)
            
            st.divider()
            col_p1, col_p2 = st.columns(2)
            temperature = col_p1.slider("Temperature", 0.0, 1.0, 0.7, 0.1)
            
            col_btn1, col_btn2 = st.columns([1, 4])
            start_batch = col_btn1.button("ğŸš€ å¼€å§‹æ‰¹é‡æµ‹è¯•", type="primary", disabled=len(selected_indices)==0)
            start_all = col_btn2.button("ğŸ”¥ æ‰§è¡Œå…¨éƒ¨ç”¨ä¾‹")

            if start_all:
                selected_indices = list(range(len(df_cases)))

            if start_batch or start_all:
                selected_cases = [df_cases.iloc[i].to_dict() for i in selected_indices]
                task_mgr.start_task(selected_cases, temperature)
                st.success("ä»»åŠ¡å·²åœ¨åå°å¯åŠ¨ï¼æ‚¨å¯ä»¥åˆ‡æ¢åˆ°å…¶ä»–é¡µé¢æŸ¥çœ‹ã€‚")
                st.rerun()

# --- é¡µé¢ 3ï¼šå†å²è®°å½• ---
elif menu == "å†å²è®°å½•":
    st.header("ğŸ“œ è¯„æµ‹å†å²è®°å½•")
    
    df_cases = get_all_test_cases()
    col_f1, col_f2 = st.columns(2)
    
    case_options = ["å…¨éƒ¨"] + df_cases['title'].tolist()
    selected_case_title = col_f1.selectbox("æŒ‰ç”¨ä¾‹ç­›é€‰", case_options)
    
    model_options = ["å…¨éƒ¨"] + get_all_models()
    selected_model = col_f2.selectbox("æŒ‰æ¨¡å‹ç­›é€‰", model_options)
    
    case_id = None
    if selected_case_title != "å…¨éƒ¨":
        case_id = df_cases[df_cases['title'] == selected_case_title]['id'].iloc[0]
    
    df_history = get_eval_history(case_id, selected_model)
    
    if not df_history.empty:
        # ä½¿ç”¨å®¹å™¨åˆ—è¡¨ä»£æ›¿ st.dataframe ä»¥æ”¯æŒç‚¹å‡»æŸ¥çœ‹
        st.write("---")
        # è¡¨å¤´
        h_col1, h_col2, h_col3, h_col4, h_col5 = st.columns([1, 3, 2, 1, 2])
        h_col1.write("**ID**")
        h_col2.write("**æµ‹è¯•ç”¨ä¾‹**")
        h_col3.write("**æ¨¡å‹**")
        h_col4.write("**å¾—åˆ†**")
        h_col5.write("**æ“ä½œ**")

        for _, row in df_history.iterrows():
            with st.container(border=True):
                r_col1, r_col2, r_col3, r_col4, r_col5 = st.columns([1, 3, 2, 1, 2])
                r_col1.write(f"{row['id']}")
                r_col2.write(f"{row['case_title']}")
                r_col3.write(f"{row['model_name']}")
                r_col4.write(f"{row['eval_score']}")
                
                btn_label = "æ”¶èµ·" if st.session_state.get(f"view_eval_{row['id']}", False) else "æŸ¥çœ‹è¯¦æƒ…"
                if r_col5.button(btn_label, key=f"btn_eval_{row['id']}"):
                    st.session_state[f"view_eval_{row['id']}"] = not st.session_state.get(f"view_eval_{row['id']}", False)
                    st.rerun()

                # è¯¦æƒ…å±•ç¤º
                if st.session_state.get(f"view_eval_{row['id']}", False):
                    st.divider()
                    col_a, col_b = st.columns(2)
                    with col_a:
                        st.write("**æœ¬åœ°æ¨¡å‹å›ç­”**")
                        st.code(row['local_response'])
                        if row['chain_of_thought']:
                            with st.expander("ğŸ’­ æŸ¥çœ‹æ€ç»´é“¾ (CoT)", expanded=True):
                                st.write(row['chain_of_thought'])
                    
                    with col_b:
                        st.write("**è¯„å§”è¯„åˆ†ä¸ç†ç”±**")
                        st.metric("å¾—åˆ†", f"{row['eval_score']}/10")
                        st.info(row['eval_comment'])
                        
                        st.write("**æ€§èƒ½æŒ‡æ ‡**")
                        st.write(f"- è€—æ—¶: {row['total_time_ms']:.2f} ms")
                        st.write(f"- ç”Ÿæˆé€Ÿåº¦: {row['tokens_per_second']:.2f} tps")
                        if 'prompt_tps' in row and row['prompt_tps'] > 0:
                            st.write(f"- é¢„è¯»é€Ÿåº¦: {row['prompt_tps']:.2f} tps")
                        if 'max_context' in row and row['max_context'] > 0:
                            st.write(f"- æ¨¡å‹ä¸Šä¸‹æ–‡: {row['max_context']} tokens")
                        st.write(f"- Tokens: {row['prompt_tokens']} (in) / {row['completion_tokens']} (out)")
                        
                        if st.button("ğŸ—‘ï¸ åˆ é™¤æ­¤æ¡è®°å½•", key=f"del_eval_{row['id']}"):
                            delete_eval_record(row['id'])
                            st.success(f"è®°å½• {row['id']} å·²åˆ é™¤")
                            st.rerun()
    else:
        st.info("æš‚æ— è¯„æµ‹è®°å½•ã€‚")

# --- é¡µé¢ 4ï¼šç»Ÿè®¡åˆ†æ ---
elif menu == "ç»Ÿè®¡åˆ†æ":
    st.header("ğŸ“Š ç»Ÿè®¡åˆ†ææŠ¥å‘Š")
    
    tab1, tab2 = st.tabs(["ä»¥æ¨¡å‹ä¸ºå•ä½", "ä»¥æµ‹è¯•é¢˜ä¸ºå•ä½"])
    
    with tab1:
        st.subheader("æ¨¡å‹æ€§èƒ½æ±‡æ€»")
        df_model_summary = get_model_summary_stats()
        if not df_model_summary.empty:
            for _, row in df_model_summary.iterrows():
                with st.container(border=True):
                    col1, col2, col3 = st.columns([3, 2, 1])
                    col1.write(f"**æ¨¡å‹: {row['model_name']}**")
                    col2.write(f"å¹³å‡åˆ†: **{row['avg_score']:.2f}** / 10")
                    col3.write(f"æµ‹è¯•æ¬¡æ•°: {row['test_count']}")
                    
                    if st.button("æŸ¥çœ‹æ¯é¢˜å¹³å‡åˆ†", key=f"model_detail_{row['model_name']}"):
                        st.session_state[f"show_detail_{row['model_name']}"] = not st.session_state.get(f"show_detail_{row['model_name']}", False)
                        st.rerun()
                    
                    if st.session_state.get(f"show_detail_{row['model_name']}", False):
                        st.write("---")
                        df_details = get_model_detail_stats(row['model_name'])
                        st.table(df_details.rename(columns={
                            'case_title': 'æµ‹è¯•é¢˜',
                            'avg_score': 'å¹³å‡åˆ†',
                            'run_count': 'è¿è¡Œæ¬¡æ•°'
                        }))
        else:
            st.info("æš‚æ— æ¨¡å‹ç»Ÿè®¡æ•°æ®ã€‚")

    with tab2:
        st.subheader("æµ‹è¯•é¢˜æ±‡æ€»")
        df_case_summary = get_case_summary_stats()
        if not df_case_summary.empty:
            for _, row in df_case_summary.iterrows():
                with st.container(border=True):
                    col1, col2, col3 = st.columns([3, 2, 1])
                    col1.write(f"**æµ‹è¯•é¢˜: {row['case_title']}**")
                    col2.write(f"å…¨æ¨¡å‹å¹³å‡åˆ†: **{row['avg_score']:.2f}** / 10")
                    col3.write(f"æ€»è¿è¡Œæ¬¡æ•°: {row['total_runs']}")
                    
                    if st.button("æŸ¥çœ‹æ¨¡å‹æ’å", key=f"case_rank_{row['case_id']}"):
                        st.session_state[f"show_rank_{row['case_id']}"] = not st.session_state.get(f"show_rank_{row['case_id']}", False)
                        st.rerun()
                    
                    if st.session_state.get(f"show_rank_{row['case_id']}", False):
                        st.write("---")
                        df_ranking = get_case_model_ranking(row['case_id'])
                        st.table(df_ranking.rename(columns={
                            'model_name': 'æ¨¡å‹åç§°',
                            'avg_score': 'å¹³å‡åˆ†',
                            'run_count': 'è¿è¡Œæ¬¡æ•°'
                        }))
        else:
            st.info("æš‚æ— æµ‹è¯•é¢˜ç»Ÿè®¡æ•°æ®ã€‚")

"""
ç®€å•æµ‹è¯•è„šæœ¬ï¼šéªŒè¯ is_remote_model å‡½æ•°
"""

def is_remote_model(model_name):
    """åˆ¤æ–­æ˜¯å¦ä¸ºè¿œç«¯æ¨¡å‹ï¼ˆåŸºäºæ¨¡å‹åç§°ï¼‰"""
    if not model_name:
        return False
    return not model_name.endswith('.gguf')

print("=" * 80)
print("æ¨¡å‹ç±»å‹æ£€æµ‹åŠŸèƒ½æµ‹è¯•")
print("=" * 80)

print("\nğŸ“‹ æµ‹è¯• is_remote_model() å‡½æ•°")
print("-" * 80)

test_cases = [
    # æœ¬åœ°æ¨¡å‹ï¼ˆ.gguf ç»“å°¾ï¼‰
    ("Qwen3-30B-A3B-Instruct-2507-IQ4_XS-3.87bpw.gguf", False, "æœ¬åœ°"),
    ("GLM-4.7-Flash-PRISM-Q3_K_M.gguf", False, "æœ¬åœ°"),
    ("DeepSeek-Coder-V2-Lite-Instruct-Q5_K_M.gguf", False, "æœ¬åœ°"),
    ("phi-4-Q6_K.gguf", False, "æœ¬åœ°"),
    
    # è¿œç«¯æ¨¡å‹ï¼ˆä¸ä»¥ .gguf ç»“å°¾ï¼‰
    ("meta-llama/llama-3.3-70b-instruct:free", True, "è¿œç«¯"),
    ("gpt-4", True, "è¿œç«¯"),
    ("mimo-v2-flash", True, "è¿œç«¯"),
    ("gemma-3-27b-it", True, "è¿œç«¯"),
    ("z-ai/glm-4.5-air:free", True, "è¿œç«¯"),
    ("openai/gpt-oss-120b:free", True, "è¿œç«¯"),
    ("minimaxai/minimax-m2.1", True, "è¿œç«¯"),
    
    # è¾¹ç•Œæƒ…å†µ
    ("", False, "æœ¬åœ°(ç©ºå­—ç¬¦ä¸²)"),
]

passed = 0
failed = 0

for model_name, expected, description in test_cases:
    result = is_remote_model(model_name)
    status = "âœ…" if result == expected else "âŒ"
    if result == expected:
        passed += 1
    else:
        failed += 1
    
    model_display = f"'{model_name}'" if model_name else "''"
    expected_str = "è¿œç«¯" if expected else "æœ¬åœ°"
    result_str = "è¿œç«¯" if result else "æœ¬åœ°"
    print(f"{status} {model_display:<55} | æœŸæœ›: {expected_str:<4} | å®é™…: {result_str:<4} | {description}")

print("\n" + "=" * 80)
print(f"æµ‹è¯•ç»“æœ: âœ… {passed} é€šè¿‡, âŒ {failed} å¤±è´¥")
print("=" * 80)

if failed == 0:
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼is_remote_model() å‡½æ•°å·¥ä½œæ­£å¸¸ã€‚")
else:
    print(f"\nâš ï¸  æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
